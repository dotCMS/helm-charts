{{- if .Values.coreServiceEnabled }}
{{- range $envName := keys $.Values.environments }}
{{- with include "myapp.mergeEnvironment" ( mergeOverwrite $ (dict "envName" $envName )) | fromYaml }}
{{- $fullName := include "dotcms.env.fullName" . }}
{{- $namespace := .Values.customerName }}
{{- $configMapName := printf "%s-%s-upgrade-metadata" .Values.customerName .Values.environment }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "dotcms.postUpgradeJobName" . }}-{{ .Release.Revision }}
  namespace: {{ .Values.customerName }}
  labels:
    helm.sh-revision: "{{ .Release.Revision }}"  
  annotations:
    "helm.sh/hook": post-upgrade,post-install
    "helm.sh/hook-weight": "5"
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  template:
    spec:
      serviceAccountName: {{ include "dotcms.serviceaccount.admin" . }}
      containers:
        - name: kubectl
          image: bitnami/kubectl:1.32.0
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -c
            - |
              echo "Checking for ConfigMap {{ $configMapName }} in namespace {{ $namespace }}..."

              UPGRADE_REQUIRED="false"
              BACKUP_RESTORE_ENABLED="false"

              if kubectl get configmap {{ $configMapName }} -n {{ $namespace }} > /dev/null 2>&1; then
                echo "ConfigMap found. Fetching replica count..."
                REPLICAS=$(kubectl get configmap {{ $configMapName }} \
                  -o jsonpath='{.data.replicas}' -n {{ $namespace }})

                UPGRADE_REQUIRED=$(kubectl get configmap {{ $configMapName }} \
                  -o jsonpath='{.data.upgradeRequired}' -n {{ $namespace }})

                BACKUP_RESTORE_ENABLED=$(kubectl get configmap {{ $configMapName }} \
                  -o jsonpath='{.data.backupRestoreEnabled}' -n {{ $namespace }})
              else
                echo "No ConfigMap found for {{ $envName }}. Assuming no upgrade required."
              fi

              # Check for completion files and update ConfigMap accordingly
              if [[ -f /tmp/backup_completed ]]; then
                echo "Backup completion file found. Updating ConfigMap..."
                kubectl patch configmap {{ $configMapName }} -n {{ $namespace }} \
                  --type merge \
                  --patch '{"data":{"backupRevision":"{{ .Release.Revision }}"}}'
                echo "ConfigMap updated with backup completion."
              elif [[ -f /tmp/restore_completed ]]; then
                echo "Restore completion file found. Updating ConfigMap..."
                kubectl patch configmap {{ $configMapName }} -n {{ $namespace }} \
                  --type merge \
                  --patch '{"data":{"restoreRevision":"{{ .Release.Revision }}"}}'
                echo "ConfigMap updated with restore completion."
              fi

              if [ "{{ .Values.scaleDownBeforeUpgrade }}" = "true" ] || [ "$UPGRADE_REQUIRED" = "true" ] || [ "$BACKUP_RESTORE_ENABLED" = "true" ]; then
                echo "Scaling up statefulset {{ $fullName }} to $REPLICAS replicas..."
                kubectl scale statefulset {{ $fullName }} --replicas=$REPLICAS -n {{ $namespace }}

                kubectl rollout status statefulset {{ $fullName }} -n {{ $namespace }}
              else
                echo "Scale up not required for {{ $envName }}. Skipping..."
              fi
          volumeMounts:
            - name: admin-shared-{{ $envName }}
              mountPath: /tmp
      volumes:
        - name: admin-shared-{{ $envName }}
          emptyDir: {}
      restartPolicy: Never
{{- end }}
{{- end }}
{{- end }}